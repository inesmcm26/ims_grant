{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_engineered = pd.read_csv('data/data_cleaned_engineered.csv')\n",
    "data_engineered.set_index('PUF_ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['sample', 'FINGOALS', 'AUTOMATED_1', 'AUTOMATED_2',\n",
    "             'HOUSING', 'LIVINGARRANGEMENT', 'SNAP', 'FRAUD2',\n",
    "             'COVERCOSTS', 'MANAGE2', 'RETIRE', 'generation',\n",
    "             'PPETHM', 'PPMARIT', 'PPREG9']\n",
    "\n",
    "num_feats = set(data_engineered.columns) - set(cat_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Passing a set as an indexer is not supported. Use a list instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# sns heatmap with annot and only on one side of the diagonal and only on correlations above 0.7\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize \u001b[39m=\u001b[39m (\u001b[39m50\u001b[39m, \u001b[39m30\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m sns\u001b[39m.\u001b[39mheatmap(data_engineered[num_feats]\u001b[39m.\u001b[39mcorr(method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mspearman\u001b[39m\u001b[39m'\u001b[39m)[data_engineered[num_feats]\u001b[39m.\u001b[39mcorr(method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mspearman\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0.7\u001b[39m]\u001b[39m.\u001b[39mdropna(how \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mall\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mdropna(how \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mall\u001b[39m\u001b[39m'\u001b[39m, axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m), annot \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, cmap \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcoolwarm\u001b[39m\u001b[39m'\u001b[39m, vmin \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, vmax \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/functionalenv/lib/python3.9/site-packages/pandas/core/frame.py:3714\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3713\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m-> 3714\u001b[0m     check_dict_or_set_indexers(key)\n\u001b[1;32m   3715\u001b[0m     key \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mitem_from_zerodim(key)\n\u001b[1;32m   3716\u001b[0m     key \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/functionalenv/lib/python3.9/site-packages/pandas/core/indexing.py:2611\u001b[0m, in \u001b[0;36mcheck_dict_or_set_indexers\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m   2603\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2604\u001b[0m \u001b[39mCheck if the indexer is or contains a dict or set, which is no longer allowed.\u001b[39;00m\n\u001b[1;32m   2605\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2606\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   2607\u001b[0m     \u001b[39misinstance\u001b[39m(key, \u001b[39mset\u001b[39m)\n\u001b[1;32m   2608\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m)\n\u001b[1;32m   2609\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mset\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m key)\n\u001b[1;32m   2610\u001b[0m ):\n\u001b[0;32m-> 2611\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   2612\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing a set as an indexer is not supported. Use a list instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2613\u001b[0m     )\n\u001b[1;32m   2615\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   2616\u001b[0m     \u001b[39misinstance\u001b[39m(key, \u001b[39mdict\u001b[39m)\n\u001b[1;32m   2617\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m)\n\u001b[1;32m   2618\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m key)\n\u001b[1;32m   2619\u001b[0m ):\n\u001b[1;32m   2620\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   2621\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing a dict as an indexer is not supported. Use a list instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2622\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Passing a set as an indexer is not supported. Use a list instead."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 5000x3000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sns heatmap with annot and only on one side of the diagonal and only on correlations above 0.7\n",
    "plt.figure(figsize = (50, 30))\n",
    "sns.heatmap(data_engineered[num_feats].corr(method = 'spearman')[data_engineered[num_feats].corr(method = 'spearman') > 0.7].dropna(how = 'all').dropna(how = 'all', axis = 1), annot = True, cmap = 'coolwarm', vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fpl            2\n",
       "VALUERANGES    2\n",
       "MORTGAGE       2\n",
       "HHEDUC         2\n",
       "PPEDUC         2\n",
       "PPHHSIZE       2\n",
       "PPINCIMP       2\n",
       "PPT18OV        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get pairs of features with correelation above 0.7\n",
    "corr = data_engineered[num_feats].corr(method = 'spearman')\n",
    "corr[corr > 0.7].notna().sum()[corr[corr > 0.7].notna().sum() > 1] # columns that are highly correlated with others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035577550171268124"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_engineered.corr(method = 'spearman')['MORTGAGE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04101976125632419"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_engineered.corr(method = 'spearman')['VALUERANGES'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feat_selection = data_engineered.copy()\n",
    "\n",
    "data_feat_selection.drop(['VALUERANGES', 'HHEDUC', 'PPT18OV'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6038, 164)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_feat_selection.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "\n",
    "We have 162 features. I want to keep only 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_feat_selection.drop('fpl', axis = 1)\n",
    "Y = data_feat_selection['fpl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size = 0.2, random_state = 0, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample_weights = X_train['finalwt']\n",
    "X_train.drop('finalwt', axis = 1, inplace = True)\n",
    "X_val_sample_weights = X_val['finalwt']\n",
    "X_val.drop('finalwt', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=[1, 2, 3], y=y_train)\n",
    "weights = {}\n",
    "for i, value in enumerate(class_weights):\n",
    "    weights[i + 1] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 3.3823529411764706, 2: 2.523510971786834, 3: 0.4332615715823466}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_weights = y_train.map({k: v for k, v in weights.items()})\n",
    "X_val_weights = y_val.map({k: v for k, v in weights.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_selection(X_train, y_train, X_val, y_val, min_feats):\n",
    "  \"\"\"\n",
    "    Function that selects the K most important features according to RFE.\n",
    "    The k is dinamically choosen by calculating the scores of the model with values of K ranging from 1 to the number of features.\n",
    "  \"\"\"\n",
    "  nr_features_list = list(range(min_feats, len(X_train.columns) +1))\n",
    "  highest_score=0\n",
    "\n",
    "  score_list = []\n",
    "\n",
    "  # to select the best nr of features to keep\n",
    "  for n in nr_features_list:\n",
    "    # create model for the RFE to use\n",
    "    model = DecisionTreeClassifier(random_state = 20)\n",
    "\n",
    "    # create RFE object to select the best n features\n",
    "    rfe = RFE(estimator = model, n_features_to_select = n)\n",
    "    X_train_rfe = rfe.fit_transform(X_train, y_train, sample_weight = X_train_sample_weights)\n",
    "    X_val_rfe = rfe.transform(X_val)\n",
    "\n",
    "    # fit the model with the selected features\n",
    "    model.fit(X_train_rfe, y_train, sample_weight = X_train_sample_weights)\n",
    "    \n",
    "    # model score\n",
    "    y_pred = model.predict(X_val_rfe)\n",
    "    score = f1_score(y_val, y_pred, average = 'weighted', sample_weight = X_val_weights)\n",
    "    score_list.append(score)\n",
    "    \n",
    "    # select the number of features that show the highest score\n",
    "    if(score>highest_score):\n",
    "      selected_features = X_train.columns[rfe.support_].values\n",
    "      highest_score = score\n",
    "\n",
    "  return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_features = rfe_selection(X_train, y_train, X_val, y_val, min_feats = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sel_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_feat_selection[np.append(sel_features, 'finalwt')]\n",
    "Y = data_feat_selection['fpl']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size = 0.2, random_state = 0, stratify = Y)\n",
    "\n",
    "X_train_sample_weights = X_train['finalwt']\n",
    "X_train.drop('finalwt', axis = 1, inplace = True)\n",
    "X_val.drop('finalwt', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(random_state = 20)\n",
    "model.fit(X_train, y_train, sample_weight = X_train_sample_weights)\n",
    "\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=[1, 2, 3], y=y_train)\n",
    "weights = {}\n",
    "for i, value in enumerate(class_weights):\n",
    "    weights[i + 1] = value\n",
    "\n",
    "X_train_weights = y_train.map({k: v for k, v in weights.items()})\n",
    "X_val_weights = y_val.map({k: v for k, v in weights.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8951053579711574"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, y_pred, average='weighted', sample_weight = X_val_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred != y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feat_selection.to_csv('data/preprocessed_data_feat_selection.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "functionalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
